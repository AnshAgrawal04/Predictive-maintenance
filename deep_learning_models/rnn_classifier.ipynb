{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporora import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: FD001\n",
      "Epoch [1/50], Loss: 0.3955\n",
      "Epoch [2/50], Loss: 0.3973\n",
      "Epoch [3/50], Loss: 0.3874\n",
      "Epoch [4/50], Loss: 0.4013\n",
      "Epoch [5/50], Loss: 0.4192\n",
      "Epoch [6/50], Loss: 0.2883\n",
      "Epoch [7/50], Loss: 0.4348\n",
      "Epoch [8/50], Loss: 0.3655\n",
      "Epoch [9/50], Loss: 0.4186\n",
      "Epoch [10/50], Loss: 0.4018\n",
      "Epoch [11/50], Loss: 0.4060\n",
      "Epoch [12/50], Loss: 0.3800\n",
      "Epoch [13/50], Loss: 0.2470\n",
      "Epoch [14/50], Loss: 0.2880\n",
      "Epoch [15/50], Loss: 0.3469\n",
      "Epoch [16/50], Loss: 0.2725\n",
      "Epoch [17/50], Loss: 0.1987\n",
      "Epoch [18/50], Loss: 0.3550\n",
      "Epoch [19/50], Loss: 0.3306\n",
      "Epoch [20/50], Loss: 0.1956\n",
      "Epoch [21/50], Loss: 0.3359\n",
      "Epoch [22/50], Loss: 0.2571\n",
      "Epoch [23/50], Loss: 0.2044\n",
      "Epoch [24/50], Loss: 0.3028\n",
      "Epoch [25/50], Loss: 0.2587\n",
      "Epoch [26/50], Loss: 0.2023\n",
      "Epoch [27/50], Loss: 0.1767\n",
      "Epoch [28/50], Loss: 0.3415\n",
      "Epoch [29/50], Loss: 0.2583\n",
      "Epoch [30/50], Loss: 0.2759\n",
      "Epoch [31/50], Loss: 0.2363\n",
      "Epoch [32/50], Loss: 0.2039\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # Output size is the number of classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Use the output of the last time step\n",
    "        return out\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing dataset: {dataset}\")\n",
    "    args.sub_dataset = dataset\n",
    "\n",
    "    train_loader, valid_loader, test_loader, test_loader_last, num_test_windows, train_visualize, engine_id = get_dataloader(\n",
    "        dir_path=args.dataset_root,\n",
    "        sub_dataset=args.sub_dataset,\n",
    "        max_rul=args.max_rul,\n",
    "        seq_length=args.sequence_len,\n",
    "        batch_size=args.batch_size,\n",
    "        use_exponential_smoothing=args.use_exponential_smoothing,\n",
    "        smooth_rate=args.smooth_rate)\n",
    "\n",
    "    input_size = args.feature_num\n",
    "    hidden_size = 64\n",
    "    num_layers = 2\n",
    "\n",
    "    # Dynamically infer the number of classes from the dataset\n",
    "    all_labels = []\n",
    "    for _, y in train_loader:\n",
    "        all_labels.extend(y.numpy().flatten())\n",
    "    output_size = len(set(all_labels))  # Dynamically calculate number of classes\n",
    "\n",
    "    num_epochs = 50\n",
    "\n",
    "    rnn_model = RNNModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        rnn_model.train()\n",
    "        for x, y in train_loader:\n",
    "            x = x.view(-1, args.sequence_len, args.feature_num).to(device)\n",
    "            y = y.view(-1).to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = rnn_model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    rnn_model.eval()\n",
    "    valid_predictions, valid_actuals = [], []\n",
    "    test_predictions, test_actuals = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x = x.view(-1, args.sequence_len, args.feature_num).to(device)\n",
    "            y = y.view(-1).to(device).long()\n",
    "            preds = rnn_model(x)\n",
    "            _, predicted = torch.max(preds, 1) \n",
    "            valid_predictions.extend(predicted.cpu().numpy())\n",
    "            valid_actuals.extend(y.cpu().numpy())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.view(-1, args.sequence_len, args.feature_num).to(device)\n",
    "            y = y.view(-1).to(device).long()\n",
    "            preds = rnn_model(x)\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "            test_predictions.extend(predicted.cpu().numpy())\n",
    "            test_actuals.extend(y.cpu().numpy())\n",
    "\n",
    "    valid_accuracy = accuracy_score(valid_actuals, valid_predictions)\n",
    "    test_accuracy = accuracy_score(test_actuals, test_predictions)\n",
    "\n",
    "    valid_classification_report = classification_report(valid_actuals, valid_predictions)\n",
    "    test_classification_report = classification_report(test_actuals, test_predictions)\n",
    "\n",
    "    metrics[dataset] = {\n",
    "        \"Validation Accuracy\": valid_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Validation Report\": valid_classification_report,\n",
    "        \"Test Report\": test_classification_report\n",
    "    }\n",
    "\n",
    "    print(f\"Dataset {dataset} Metrics:\")\n",
    "    print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Validation Classification Report:\\n{valid_classification_report}\")\n",
    "    print(f\"Test Classification Report:\\n{test_classification_report}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(test_actuals, test_predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=np.arange(output_size),\n",
    "                yticklabels=np.arange(output_size))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix for {dataset}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
